{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee0022e7-e52b-44d2-b18d-f24b5d3155d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mjbridgnell-admin\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy Pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bb6c14-6cc9-45f0-8be2-16cd600416d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db4a6daf-a578-4b31-bf94-1994af7945f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_preprocess(directory):\n",
    "    \"\"\"\n",
    "    Helper function to load and preprocess handwritten images and their labels.\n",
    "    Args:\n",
    "        directory (str): Path to the directory containing image files.\n",
    "    Returns:\n",
    "        images (torch.Tensor): Tensor of image data (num_images, 1, 28, 28).\n",
    "        labels (torch.Tensor): Tensor of labels corresponding to the images.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=0.5, std=0.5)\n",
    "    ])\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\"):\n",
    "            label = int(filename.split('-')[0])\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            image = Image.open(image_path).convert('L')\n",
    "            image_tensor = transform(image)\n",
    "            images.append(image_tensor)\n",
    "            labels.append(label)\n",
    "    \n",
    "    images = torch.stack(images)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "directory_path = \"./digits\"\n",
    "images, labels = load_images_and_preprocess(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b45572-f7c6-4b7f-8aaf-6d16753583fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandwrittenDigitsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_files = [f for f in os.listdir(directory) if f.endswith(\".png\")]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=0.5, std=0.5)\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.image_files[idx]\n",
    "        label = int(file_name.split('-')[0])\n",
    "        image_path = os.path.join(self.directory, file_name)\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = HandwrittenDigitsDataset(directory_path)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9bbd6f-a5b6-4bac-808a-7c1e07be9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ccffa9-9698-4142-89d5-7befee95dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_loader, test_loader = load_mnist_data(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0908bbf-aec3-433e-aa28-b3e1962c3b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.2409\n",
      "Epoch [1/5], Step [200/938], Loss: 0.2858\n",
      "Epoch [1/5], Step [300/938], Loss: 0.3332\n",
      "Epoch [1/5], Step [400/938], Loss: 0.2582\n",
      "Epoch [1/5], Step [500/938], Loss: 0.3940\n",
      "Epoch [1/5], Step [600/938], Loss: 0.1924\n",
      "Epoch [1/5], Step [700/938], Loss: 0.1441\n",
      "Epoch [1/5], Step [800/938], Loss: 0.1508\n",
      "Epoch [1/5], Step [900/938], Loss: 0.1140\n",
      "Epoch [2/5], Step [100/938], Loss: 0.1090\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0664\n",
      "Epoch [2/5], Step [300/938], Loss: 0.1735\n",
      "Epoch [2/5], Step [400/938], Loss: 0.0596\n",
      "Epoch [2/5], Step [500/938], Loss: 0.2743\n",
      "Epoch [2/5], Step [600/938], Loss: 0.1641\n",
      "Epoch [2/5], Step [700/938], Loss: 0.1280\n",
      "Epoch [2/5], Step [800/938], Loss: 0.1243\n",
      "Epoch [2/5], Step [900/938], Loss: 0.1820\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0975\n",
      "Epoch [3/5], Step [200/938], Loss: 0.1467\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0202\n",
      "Epoch [3/5], Step [400/938], Loss: 0.0790\n",
      "Epoch [3/5], Step [500/938], Loss: 0.1910\n",
      "Epoch [3/5], Step [600/938], Loss: 0.1775\n",
      "Epoch [3/5], Step [700/938], Loss: 0.0948\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0265\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1240\n",
      "Epoch [4/5], Step [100/938], Loss: 0.1397\n",
      "Epoch [4/5], Step [200/938], Loss: 0.0211\n",
      "Epoch [4/5], Step [300/938], Loss: 0.1224\n",
      "Epoch [4/5], Step [400/938], Loss: 0.0551\n",
      "Epoch [4/5], Step [500/938], Loss: 0.2120\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0438\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0570\n",
      "Epoch [4/5], Step [800/938], Loss: 0.0080\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0846\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0683\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0719\n",
      "Epoch [5/5], Step [300/938], Loss: 0.0241\n",
      "Epoch [5/5], Step [400/938], Loss: 0.2471\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0221\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0957\n",
      "Epoch [5/5], Step [700/938], Loss: 0.1219\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0373\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0473\n"
     ]
    }
   ],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train(model, device, train_loader, optimizer, criterion, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93747acc-bc79-4977-818b-ed3c553a9a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.22%\n",
      "Avg Test Loss: 0.0907\n"
     ]
    }
   ],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Avg Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "test(model, device, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5933936b-adb1-4a21-a8a4-0a82023059ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.38%\n",
      "Avg Test Loss: 0.2896\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model using your own handwritten digits\n",
    "fine_tune_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "train(model, device, fine_tune_loader, optimizer, criterion, epochs=5)\n",
    "test(model, device, fine_tune_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a8bbd-e3c0-46f2-856a-9325092aabff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
